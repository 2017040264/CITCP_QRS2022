{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '显著性检验_result.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19500/1380107136.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpure_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'detected'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'missed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpure_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpure_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'env'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rewardfun'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"iteration\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpure_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'显著性检验_result.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '显著性检验_result.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_pickle(\"RQ2_rq\")#1064460条数据\n",
    "#pure_df = df[(df['detected'] + df['missed'] > 0)]#248040条数据\n",
    "pure_df = df[(df['detected'] + df['missed'] > 0)]\n",
    "pure_df = pure_df.groupby(['env', 'rewardfun' ,\"iteration\"], as_index=False).mean()\n",
    "pure_df.to_csv(os.path.join('显著性检验_result.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显著性检验： apache_commons napfd 6.305087850306025e-20 False\n",
      "显著性检验： apache_commons recall 0.008568241399048639 False\n",
      "显著性检验： apache_commons ttf 7.935666603948265e-12 False\n",
      "显著性检验： apache_drill napfd 1.1674900837472714e-43 False\n",
      "显著性检验： apache_drill recall 2.6859221458284147e-24 False\n",
      "显著性检验： apache_drill ttf 7.963110044009674e-20 False\n",
      "显著性检验： apache_hive napfd 0.6172027467108139 True\n",
      "显著性检验： apache_hive recall 0.9330266411294721 True\n",
      "显著性检验： apache_hive ttf 0.5215155256194511 True\n",
      "显著性检验： apache_parquet napfd 6.719682775141114e-14 False\n",
      "显著性检验： apache_parquet recall 0.000586555610683357 False\n",
      "显著性检验： apache_parquet ttf 7.305763011785246e-12 False\n",
      "显著性检验： apache_tajo napfd 7.088460431476687e-21 False\n",
      "显著性检验： apache_tajo recall 1.1422718410468766e-14 False\n",
      "显著性检验： apache_tajo ttf 0.08902320891883547 True\n",
      "显著性检验： dspace napfd 1.4013743861451064e-29 False\n",
      "显著性检验： dspace recall 4.272932127867653e-24 False\n",
      "显著性检验： dspace ttf 2.0260628790462573e-30 False\n",
      "显著性检验： google_auto napfd 4.628989905929767e-49 False\n",
      "显著性检验： google_auto recall 3.728212740832756e-51 False\n",
      "显著性检验： google_auto ttf 5.86681751237529e-16 False\n",
      "显著性检验： google_closure napfd 2.6638250101386383e-26 False\n",
      "显著性检验： google_closure recall 1.5565303615334818e-25 False\n",
      "显著性检验： google_closure ttf 1.3705736067907244e-21 False\n",
      "显著性检验： google_guava napfd 6.029952867525394e-07 False\n",
      "显著性检验： google_guava recall 3.542801285856119e-06 False\n",
      "显著性检验： google_guava ttf 6.434217869160462e-06 False\n",
      "显著性检验： iofrol napfd 4.6628120412021295e-20 False\n",
      "显著性检验： iofrol recall 4.277970940017106e-19 False\n",
      "显著性检验： iofrol ttf 2.8446049610015024e-12 False\n",
      "显著性检验： mybatis napfd 7.317652760833933e-05 False\n",
      "显著性检验： mybatis recall 0.003459486785807597 False\n",
      "显著性检验： mybatis ttf 2.718964748560006e-07 False\n",
      "显著性检验： paintcontrol napfd 1.4098486641372593e-13 False\n",
      "显著性检验： paintcontrol recall 3.324212185026462e-11 False\n",
      "显著性检验： paintcontrol ttf 1.1205409664366855e-16 False\n",
      "显著性检验： rails napfd 7.606178125713324e-12 False\n",
      "显著性检验： rails recall 0.0005566551283845891 False\n",
      "显著性检验： rails ttf 3.134633370376065e-10 False\n"
     ]
    }
   ],
   "source": [
    "for column, env in enumerate(sorted(pure_df['env'].unique())):\n",
    "    for title in ['napfd','recall','ttf']:\n",
    "        a=0 # new is better than old\n",
    "        b=0 # new and old are queal\n",
    "        c=0 # new is lower tha old\n",
    "        env_df=pure_df[pure_df[\"env\"].isin([env])]\n",
    "        for iter in sorted(env_df['step'].unique()):\n",
    "\n",
    "            iter_df=env_df[env_df[\"step\"].isin([iter])]\n",
    "            \n",
    "            x=iter_df[iter_df[\"rewardfun\"].isin(['add_tcfail_1'])]\n",
    "            y=iter_df[iter_df[\"rewardfun\"].isin(['tcfail'])]\n",
    "            new=np.array(x[title],dtype='float64')\n",
    "            old=np.array(y[title],dtype='float64')\n",
    "            #print(type(new),type(old))\n",
    "            #print(new.shape,old.shape)\n",
    "            res = ttest_ind(new, old).pvalue\n",
    "            \n",
    "            # new=str(x[title].mean())#.split()[1]\n",
    "            # old=str(y[title].mean())#.split()[1]\n",
    "            # if new>old:\n",
    "            #     a+=1\n",
    "            # elif new==old:\n",
    "            #     b+=1\n",
    "            # else:\n",
    "            #     c+=1\n",
    "            #print(new,old)\n",
    "            #break\n",
    "\n",
    "        #print(env,title,a,b,c)\n",
    "        print(\"显著性检验：\",env,title,res,res>0.01)\n",
    "        #break\n",
    "        \n",
    "    \n",
    "    #break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for column, env in enumerate(sorted(pure_df['env'].unique())):\n",
    "    for title in ['napfd','recall','ttf']:\n",
    "        a=0 # new is better than old\n",
    "        b=0 # new and old are queal\n",
    "        c=0 # new is lower tha old\n",
    "        env_df=pure_df[pure_df[\"env\"].isin([env])]\n",
    "        for iter in sorted(env_df['iteration'].unique()):\n",
    "\n",
    "            iter_df=env_df[env_df[\"iteration\"].isin([iter])]\n",
    "            \n",
    "            x=iter_df[iter_df[\"agent\"].isin(['mlp_cla_new'])]\n",
    "            y=iter_df[iter_df[\"agent\"].isin(['mlp_cla_old'])]\n",
    "            new=np.array(x[title],dtype='float32')\n",
    "            old=np.array(y[title],dtype='float32')\n",
    "            #print(type(new),type(old))\n",
    "            #print(new)\n",
    "            res = ttest_ind(new, old).pvalue\n",
    "            \n",
    "            # new=str(x[title].mean())#.split()[1]\n",
    "            # old=str(y[title].mean())#.split()[1]\n",
    "            # if new>old:\n",
    "            #     a+=1\n",
    "            # elif new==old:\n",
    "            #     b+=1\n",
    "            # else:\n",
    "            #     c+=1\n",
    "            #print(new,old)\n",
    "            #break\n",
    "\n",
    "        #print(env,title,a,b,c)\n",
    "        print(\"显著性检验：\",env,title,res,res>0.01)\n",
    "        #break\n",
    "        \n",
    "        \n",
    "    #break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for column, env in enumerate(sorted(pure_df['env'].unique())):\n",
    "    for title in ['napfd','recall','ttf']:\n",
    "        a=0 # new is better than old\n",
    "        b=0 # new and old are queal\n",
    "        c=0 # new is lower tha old\n",
    "        env_df=pure_df[pure_df[\"env\"].isin([env])]\n",
    "        for iter in sorted(env_df['iteration'].unique()):\n",
    "\n",
    "            iter_df=env_df[env_df[\"iteration\"].isin([iter])]\n",
    "            for step in sorted(iter_df['step'].unique()):\n",
    "\n",
    "                #print(column,env,iter,step)\n",
    "                tdf=iter_df[iter_df[\"step\"].isin([step])]\n",
    "                x=tdf[tdf[\"agent\"].isin(['mlp_cla_new'])]\n",
    "                y=tdf[tdf[\"agent\"].isin(['mlp_cla_old'])]\n",
    "                new=str(x[title]).split()[1]\n",
    "                old=str(y[title]).split()[1]\n",
    "                if new>old:\n",
    "                    a+=1\n",
    "                elif new==old:\n",
    "                    b+=1\n",
    "                else:\n",
    "                    c+=1\n",
    "                #print(str(x[title]).split()[1],str(y[title]).split()[1])\n",
    "            #     break\n",
    "            # break\n",
    "        print(env,title,a,b,c)\n",
    "        #break\n",
    "    #break\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
